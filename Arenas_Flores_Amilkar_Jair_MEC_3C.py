# -*- coding: utf-8 -*-
"""Copia de Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dYna3Do8LrZRQzoIjB4VB3Ey32q7b3OJ

**This program was taken form the book "Introduction to
Machine
Learning
with Python**
"""

import sys
print("Python version: {}".format(sys.version))
import pandas as pd
print("pandas version: {}".format(pd.__version__))
import matplotlib
print("matplotlib version: {}".format(matplotlib.__version__))
import numpy as np
print("NumPy version: {}".format(np.__version__))
import scipy as sp
print("SciPy version: {}".format(sp.__version__))
import IPython
print("IPython version: {}".format(IPython.__version__))
import sklearn
print("scikit-learn version: {}".format(sklearn.__version__))

"""We will use an irirs data set which will be returned to us by load_iris which is a Bunch object, works as a dictionary and contains codes and values"""

from sklearn.datasets import load_iris
iris_dataset = load_iris()

"""The key DESCR is only a short descrpcion of the dataset"""

print("Keys of iris_dataset: \n{}".format(iris_dataset.keys()))

print(iris_dataset['DESCR'][:193] + "\n...")

"""The key target_names is an array of strings and this key contain some species of flower that the dataset have to predict"""

print("Target names: {}".format(iris_dataset['target_names']))

"""feature_names is a list of strings that give the description of the features"""

print("Feature names: \n{}".format(iris_dataset['feature_names']))

"""This part of the code is to the numeric measurements of sepal length, sepal width, petal length, and petal width in a NumPy
array
"""

print("Type of data: {}".format(type(iris_dataset['data'])))

"""With this code we obtain the quantiti of flowers and now we want to clasiffy them in four measurements"""

print("Shape of data: {}".format(iris_dataset['data'].shape))

"""this is the part where we clisiffy the flower according with the measurements that we taken.
The rows in the data array correspond to flowers, while the columns represent the
four measurements that were taken for each flower:
"""

print("First five columns of data:\n{}".format(iris_dataset['data'][:5]))

"""The code "target" contains the differents species for each flower that were measured"""

print("Type of target: {}".format(type(iris_dataset['target'])))

""""target" have one entry per flower"""

print("Shape of target: {}".format(iris_dataset['target'].shape))

"""In this part the the species are encoded as integers from 0 to 2"""

print("Target:\n{}".format(iris_dataset['target']))

"""This the part of the train to the dataset, where we will build a machine learning model to know the of prediton accuaricy of our dataset"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
 iris_dataset['data'], iris_dataset['target'], random_state=0)

print("X_train shape: {}".format(X_train.shape))
print("y_train shape: {}".format(y_train.shape))

print("X_test shape: {}".format(X_test.shape))
print("y_test shape: {}".format(y_test.shape))

"""Now we will visualize the data using a scatter plot. The scatter plot of the data puts one feature along the x-axis and another
along the y-axis, and draws a dot for each data point
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn import datasets

iris_dataset = datasets.load_iris()
X = iris_dataset.data
Y = iris_dataset.target

iris_dataframe = pd.DataFrame(X, columns=iris_dataset.feature_names)
# create a scatter matrix from the dataframe, color by y_train
grr = pd.plotting.scatter_matrix(iris_dataframe, c=Y, figsize=(15, 15), marker='o',
                                 hist_kwds={'bins': 20}, s=60, alpha=.8)

"""The next cell is just to import one of the libraries that we need to the dataset"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=1)

"""Now we going to build the model on the training data using  as arguments the NumPy array X_train containing the training data and
the NumPy array y_train of the corresponding training labels
"""

knn.fit(X_train, y_train)

"""And now we can make prediction with the new model on the data. First we need the measure of one flower"""

X_new = np.array([[5, 2.9, 1, 0.2]])
print("X_new.shape: {}".format(X_new.shape))

"""And then we call the predict method of the knn object"""

prediction = knn.predict(X_new)
print("Prediction: {}".format(prediction))
print("Predicted target name: {}".format(
 iris_dataset['target_names'][prediction]))

"""In this part of the program we will measure how well the model works by computing the accuarucy"""

y_pred = knn.predict(X_test)
print("Test set predictions:\n {}".format(y_pred))

"""The result of the x test saves it to the new variable under the given parameters"""

print("Test set score: {:.2f}".format(np.mean(y_pred == y_test)))

"""The result are shown below"""

print("Test set score: {:.2f}".format(knn.score(X_test, y_test)))

"""And finally the results of the training"""

X_train, X_test, y_train, y_test = train_test_split(
 iris_dataset['data'], iris_dataset['target'], random_state=0)
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train, y_train)
print("Test set score: {:.2f}".format(knn.score(X_test, y_test)))